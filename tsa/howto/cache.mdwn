A caching service is a set of services keeping a smaller cache of
content in memory to speed up access to resources on a slower backend
server.

[[!toc levels=3]]

# Discussion

A discussion of the design of the new service, mostly.

## Overview

The original goal of this project is to create a pair of caching
servers in front of the blog to reduce the bandwidth costs we're being
charged there.

## Goals

### Must have

 * reduce the traffic on the blog, hosted at a costly provider (#32090)
 * HTTPS support in the frontend and backend
 * deployment through Puppet
 * anonymized logs

### Nice to have

 * provide a frontend for our existing mirror infrastructure, a
   home-made CDN for TBB and other releases
 * no on-disk logs
 * cute dashboard or grafana integration
 * well-maintained upstream Puppet module

### Approvals required

 * approved and requested by vegas

## Non-Goals

 * global CDN for users outside of TPO
 * geoDNS

## Proposed Solution

TBD (To Be Determined). Considering either Apache Traffic Server or
Nginx on a pair of servers.

TODO: In the gnt-fsn cluster if cost-effective, otherwise maybe in two
Hetzner VMs?

## Launch checklist

See [#32239](https://trac.torproject.org/projects/tor/ticket/32239).

## Benchmarking procedures

Will require a test VM (or two?) to hit the caches.

### Siege

Siege configuration sample:

```
verbose = false
fullurl = true
concurrent = 100
time = 2M
url = http://www.example.com/
delay = 1
internet = false
benchmark = true
```

Might require this, which might work only with varnish:

```
proxy-host = 209.44.112.101
proxy-port = 80
```

Alternative is to hack `/etc/hosts`.

### apachebench

Classic commandline:

    ab2 -n 1000 -c 100 -X cache01.torproject.org https://example.com/

### Other tools

Siege has trouble going above ~100 concurrent clients because of its
design (and ulimit) limitations. Its interactive features are also
limited, here's a set of interesting alternatives:

 * [bombardier](https://github.com/codesenberg/bombardier) - golang, HTTP/2, better performance than siege in
   my (2017) tests
 * [boom](https://github.com/tarekziade/boom) - python rewrite of apachebench, supports duration,
   HTTP/2, not in debian, unsearchable name
 * [go-wrk](https://github.com/adjust/go-wrk/) - golang rewrite of wrk with HTTPS, had performance
   issues in my first tests (2017), [no duration target](https://github.com/adjust/go-wrk/issues/2), not in
   Debian
 * [hey](https://github.com/rakyll/hey) - golang rewrite of apachebench, similar to boom, not in
   debian, unsearchable name
 * [Jmeter](https://jmeter.apache.org/) - interactive behavior, can replay recorded sessions
   from browsers
 * [Locust](https://locust.io/) - distributed, can model login and interactive
   behavior, not in Debian
 * [Tsung](http://tsung.erlang-projects.org/1/01/about/) - multi-protocol, distributed, erlang
 * [wrk](https://github.com/wg/wrk/) - multithreaded, epoll, Lua scriptable, no HTTPS

## Cost

Somewhere between 11EUR and 100EUR/mth for bandwidth and hardware.

We're getting apparently around 2.2M "page views" per month at
Pantheon. That is about 1 hit per second and 12 terabyte per month,
36Mbit/s on average:

    $ qalc
    > 2 200 000 ∕ (30d) to hertz

      2200000 / (30 * day) = approx. 0.84876543 Hz

    > 2 200 000 * 5Mibyte

      2200000 * (5 * mebibyte) = 11.534336 terabytes

    > 2 200 000 * 5Mibyte/(30d) to megabit / s

      (2200000 * (5 * mebibyte)) / (30 * day) = approx. 35.599802 megabits / s

Hetzner charges 1EUR/TB/month over our 1TB quota, so bandwidth would
cost 11EUR/month on average. If costs become prohibitive, we could
switch to a Hetzner VM which includ 20TB of traffic per month at costs
ranging from 3EUR/mth to 30EUR/mth depending on the VPS size (between
1 vCPU, 2GB ram, 20GB SSD and 8vCPU, 32GB ram and 240GB SSD).

Dedicated servers start at 34EUR/mth (`EX42`, 64GB ram 2x4TB HDD) for
unlimited gigabit.

## Alternatives considered

Four alternatives were seriously considered:

 * Apache Traffic Server
 * Nginx proxying + caching
 * Varnish + stunnel
 * Fastly

Other alternatives were ignored:

 * [Apache HTTPD caching](https://httpd.apache.org/docs/2.4/caching.html) - performance expected to be sub-par
 * [Envoy][] - [not designed for caching](https://github.com/envoyproxy/envoy/issues/868), [external cache support
   planned in 2019](https://blog.getambassador.io/envoy-proxy-in-2019-security-caching-wasm-http-3-and-more-e5ba82da0197?gi=82c1a78157b8)
 * [HAproxy](https://www.haproxy.com/) - [not designed to cache large objects](https://www.haproxy.com/documentation/aloha/9-5/traffic-management/lb-layer7/caching-small-objects/)
 * [Nuster](https://github.com/jiangwenyuan/nuster) - new project, not packaged in Debian (based on
   HAproxy), performance [comparable with nginx and varnish](https://github.com/jiangwenyuan/nuster/wiki/Web-cache-server-performance-benchmark:-nuster-vs-nginx-vs-varnish-vs-squid#results)
   according to upstream, although impressive improvements
 * [Polipo](https://en.wikipedia.org/wiki/Polipo) - not designed for production use
 * [Squid](http://www.squid-cache.org/) - not designed as a reverse proxy
 * [Traefik](https://traefik.io/) - [not designed for caching](https://github.com/containous/traefik/issues/878)

[Envoy]: https://www.envoyproxy.io/
### Apache Traffic Server

Pros:

 * HTTPS
 * HTTP/2
 * industry leader (behind cloudflare)
 * out of the box clustering support

Cons:

 * load balancing is an experimental plugin (at least in 2016)
 * no static file serving? or slower?
 * no commercial support
 * configuration seems a bit obscure

Used by Yahoo, Apple and Comcast.

### Nginx

Pros:

 * provides full webserver stack means much more flexibility,
   possibility of converging over a single solution across the
   infrastructure
 * very popular
 * load balancing (but no active check in free version)
 * can serve static content
 * HTTP/2
 * HTTPS

Cons:

 * provides full webserver stack (!) means larger attack surface
 * no ESI or ICP?
 * does not cache out of the box, requires config which might imply
   lesser performance
 * opencore model with paid features, especially "active health
   checks", "Cache Purging API" (although there are [hackish ways to
   clear the cache](https://stackoverflow.com/questions/6236078/how-to-clear-the-cache-of-nginx) and [a module](https://github.com/nginx-modules/ngx_cache_purge)), and "session persistence
   based on cookies"
 * most plugins are statically compiled in different "flavors",
   although it's possible to have dynamic modules

Used by Cloudflare, [Dropbox](https://blogs.dropbox.com/tech/2017/09/optimizing-web-servers-for-high-throughput-and-low-latency/), MaxCDN and Netflix.

### Varnish

Pros:

 * specifically built for caching
 * very flexible
 * grace mode can keep objects even after TTL expired (when backends
   go down)
 * third most popular, after Cloudflare and ATS

Cons:

 * no HTTPS support on frontend or backend in the free version, would
   require stunnel hacks
 * configuration is compiled and a bit weird
 * static content needs to be generated in the config file, or sidecar
 * no HTTP/2 support

Used by Fastly.

### Fastly itself

We could just put Fastly in front of all this and shove the costs on
there.

Pros:

 * easy
 * possibly free

Cons:

 * might go over our quotas during large campaigns
 * sending more of our visitors to Fastly, non-anonymously

## Sources

Benchmarks:

 * [Bizety: Nginx vs Varnish vs Apache Traffic Server - High Level
   Comparison](https://www.bizety.com/2016/01/07/nginx-vs-varnish-vs-apache-traffic-server-high-level-comparison/) - "Each proxy server has strengths and weakness"
 * [ScaleScale: Nginx vs Varnish: which one is better?](https://www.scalescale.com/tips/nginx/nginx-vs-varnish/) - nginx +
   tmpfs good alternative to varnish
 * [garron.me: Nginx + Varnish compared to Nginx](https://www.garron.me/en/go2linux/nginx-varnish-vs-nginx-alone-compared.html) - equivalent
 * [Uptime Made Easy: Nginx or Varnish Which is Faster?](http://www.uptimemadeeasy.com/cloud/nginx-or-varnish-which-is-faster/) -
   equivalent
 * [kpayne.me: Apache Traffic Server as a Reverse Proxy](https://kpayne.me/2012/04/10/apache-traffic-server-as-a-reverse-proxy/) -
   "According to blitz.io, Varnish and Traffic Server benchmark
   results are close. According to ab, Traffic Server is twice as fast
   as Varnish"
 * [University of Oslo: Performance Evaluation of the Apache Traffic
   Server and Varnish Reverse Proxies](https://pdfs.semanticscholar.org/157b/bec8591a9fdb21e90831309f10ff6705b70d.pdf) - "Varnish seems the more
   promising reverse proxy server"
 * [Loggly: Benchmarking 5 Popular Load Balancers: Nginx, HAProxy,
   Envoy, Traefik, and ALB](https://www.loggly.com/blog/benchmarking-5-popular-load-balancers-nginx-haproxy-envoy-traefik-and-alb/)

Tutorials and documentation:

 * [Apache.org: Why Apache Traffic Server](https://svn.apache.org/repos/infra/websites/production/trafficserver/content/why-ats.html) - upstream docs
 * [czerasz.com: Nginx Caching Tutorial - You Can Run Faster](https://czerasz.com/2015/03/30/nginx-caching-tutorial/) -
   tutorial
 * [Igor Cicimov: Apache Traffic Server as Caching Reverse Proxy](https://icicimov.github.io/blog/server/Apache-Traffic-Server-as-Caching-Reverse-Proxy/) -
   tutorial, "Apache TS presents a stable, fast and scalable caching
   proxy platform"
 * [Datanyze.com: Web Accelerators Market Share Report](https://www.datanyze.com/market-share/accelerators)
