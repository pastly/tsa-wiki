# Reference

This documents generally how things are setup.

### Before it all starts

- `puppet.tpo` is currently being run on `pauli.tpo`
- This is where the tor-puppet git repo lives
- The repo has hooks to populate `/etc/puppet` with its contents, most
  notably the modules directory.
- All paths in this document are relative to the root of this
  repository.

### File layout

- The root of definitions and execution is found in
  `tor-puppet/manifests/site.pp`.

- `local.yaml` (modules/torproject_org/misc/local.yaml) defines
  services and list which host(s) supply each service. local.yaml is
  read by [site.pp](manifests/site.pp) for setting up the $localinfo
  and $nodeinfo variables.

- `roles init.pp` (modules/roles/manifests/init.pp) maps services to
  roles, using the `$nodeinfo` variable.

- `torproject.org init.pp` (modules/torproject_org/manifests/init.pp)
  performs basic host initialisation, like configuring Debian mirrors
  and APT sources, installing a base set of packages, configuring
  puppet and timezone, setting up a bunch of rc-files and running
  ud-replicate.

- `hoster.yaml` (modules/torproject_org/misc/hoster.yaml) defines
  hosting providers and specifies things like which net blocks they
  use, if they have a DNS resolver or a debian mirror. hoster.yaml is
  read by
  - the `nodeinfo()` function
    (modules/puppetmaster/lib/puppet/parser/functions/nodeinfo.rb),
    used for setting up the `$nodeinfo` variable
  - `ferm's def.conf template` (modules/ferm/templates/defs.conf.erb)
  - the `entropy provider`
    (modules/puppetmaster/lib/puppet/parser/functions/entropy_provider.rb)
    TODO

### Generating secrets, an example

- `bacula::director` inherits `bacula` which defines
- `$bacula_director_secret` using 
- `hkdf()` and generates
- `/etc/bacula/bacula-dir.conf` using that

### Custom facts

`modules/torproject_org/lib/facter/software.rb` defines our custom
facts, making it possible to get answer to questions like "Is this
host running apache2?" byt simply looking at a puppet variable.

### Misc

- `puppet-lint` is a thing
- TODO: how to debug things

# How to guides

Listing all hosts under puppet
==============================

This will list all active hosts known to the Puppet master:

    ssh -t pauli.torproject.org 'sudo -u postgres psql puppetdb -P pager=off -A -t -c "SELECT c.certname FROM certnames c WHERE c.deactivated IS NULL"'

The following will list all hosts under Puppet and their `virtual`
value:

    ssh -t pauli.torproject.org "sudo -u postgres psql puppetdb -P pager=off -F',' -A -t -c \"SELECT c.certname, value_string FROM factsets fs INNER JOIN facts f ON f.factset_id = fs.id INNER JOIN fact_values fv ON fv.id = f.fact_value_id INNER JOIN fact_paths fp ON fp.id = f.fact_path_id INNER JOIN certnames c ON c.certname = fs.certname WHERE fp.name = 'virtual' AND c.deactivated IS NULL\""  | tee hosts.csv

The resulting file is a Comma-Seperated Value (CSV) file which can be
used for other purposes later.

Possible values of the `virtual` field can be obtain with a similar
query:
    
    ssh -t pauli.torproject.org "sudo -u postgres psql puppetdb -P pager=off -A -t -c \"SELECT DISTINCT value_string FROM factsets fs INNER JOIN facts f ON f.factset_id = fs.id INNER JOIN fact_values fv ON fv.id = f.fact_value_id INNER JOIN fact_paths fp ON fp.id = f.fact_path_id WHERE fp.name = 'virtual';\""

The currently known values are: `kvm`, `physical`, and `xenu`.

## Other ways of extracting a host list

 * Using the [PuppetDB API][]:

        curl -s -G http://localhost:8080/pdb/query/v4/facts  | jq -r ".[].certname"

   The [fact API][] is quite extensive and allows for very complex
   queries. For example, this shows all hosts with the `apache2` fact
   set to `true`:

        curl -s -G http://localhost:8080/pdb/query/v4/facts --data-urlencode 'query=["and", ["=", "name", "apache2"], ["=", "value", true]]' | jq -r ".[].certname"

   This will list all hosts sorted by their report date, older first,
   followed by the timestamp, space-separated:

        curl -s -G http://localhost:8080/pdb/query/v4/nodes  | jq -r 'sort_by(.report_timestamp) | .[] | "\(.certname) \(.report_timestamp)"' | column -s\  -t

 * Using [Cumin][], see below

 * Using LDAP:
 
        HOSTS=$(ssh alberti.torproject.org 'ldapsearch -h db.torproject.org -x -ZZ -b dc=torproject,dc=org -LLL "hostname=*.torproject.org" hostname | awk "\$1 == \"hostname:\" {print \$2}" | sort')
        for i in `echo $HOSTS`; do mkdir hosts/x-$i 2>/dev/null || continue; echo $i; ssh $i ' ...'; done

    the mkdir is so that I can run the same command in many terminal
    windows and each host gets only one once

 [PuppetDB API]: https://puppet.com/docs/puppetdb/4.3/api/index.html
 [fact API]: https://puppet.com/docs/puppetdb/4.3/api/query/v4/facts.html
 [Cumin]: https://doc.wikimedia.org/cumin/master/introduction.html

Batch jobs on all hosts
=======================

With that trick, a job can be ran on all hosts with
[parallel-ssh][], for example, check the uptime:

    cut -d, -f1 hosts.hsv | parallel-ssh -i -h /dev/stdin uptime

This would do the same, but only on physical servers:

    grep 'physical$' hosts.hsv | cut -d -f1 | parallel-ssh -i -h /dev/stdin uptime

This would fetch the `/etc/motd` on all machines:

    cut -d -f1 hosts.csv | parallel-slurp -h /dev/stdin -L motd /etc/motd motd

To run batch commands through sudo that requires a password, you will need to fool both sudo and ssh a little more:

    cut -d -f1 hosts.csv | parallel-ssh -P -I -i -x -tt -h /dev/stdin -o pvs sudo pvs

You should then type your password then Control-d. Warning: this will
show your password on your terminal and probably in the logs as well. 

## Using Cumin

You can also use [Cumin][] to operate arbitrary shell commands on
Puppet hosts or a subset of hosts. First, install Cumin and setup a
tunnel to connect to the Puppet locally:

    virtualenv --python=python3 ~/.virtualenvs/cumin
    ~/.virtualenvs/cumin/bin/pip3 install cumin
    ssh -L8080:localhost:8080 pauli.torproject.org

Notice how Cumin is installed in a [Python virtualenv][]: it is not
yet [in Debian][]. You'll also need a patch to enable plain HTTP
access, see [this bug report][]. You might also want to disable the
[root check][] as well. Then drop the following configuration in
`~/.config/cumin/config.yaml`:

    transport: clustershell
    puppetdb:
        host: localhost
        scheme: http
        port: 8080
        api_version: 4  # Supported versions are v3 and v4. If not specified, v4 will be used.
    log_file: cumin.log
    default_backend: puppetdb

From here on we'll assume you use the following alias:

    alias cumin="~/.virtualenvs/cumin/bin/cumin --config ~/.config/cumin/config.yaml"

This will run the `uptime` command on all hosts:

    cumin '*' uptime

To run against only a subset, you need to use the Cumin grammar, which
is [briefly described in the Wikimedia docs][]. For example, this
will run the same command only on physical hosts:

    cumin 'F:virtual=physical' uptime

Just check the monitoring server:

    cumin 'R:class=roles::monitoring' uptime

Any Puppet fact or class can be queried that way. This also serves as
a ad-hoc interface to query PuppetDB for certain facts, as you don't
have to provide a command. In that case, `cumin` runs in "dry mode"
and will simply show which hosts match the request:

    $ cumin 'F:virtual=physical'
    16 hosts will be targeted:
    [...]

[root check]: https://phabricator.wikimedia.org/T218440
[this bug report]: https://phabricator.wikimedia.org/T218441
[in Debian]: https://bugs.debian.org/924685
[Python virtualenv]: https://virtualenv.pypa.io/
[briefly described in the Wikimedia docs]: https://wikitech.wikimedia.org/wiki/Cumin#PuppetDB_host_selection
[parallel-ssh]: https://code.google.com/archive/p/parallel-ssh/
